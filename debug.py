from sentence_transformers import SentenceTransformer
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

# ğŸ”¹ Step 1: Load HuggingFace embedding model
model_name = "sentence-transformers/all-MiniLM-L6-v2"  # ya jo bhi model use kiya tha
embedding_model = HuggingFaceEmbeddings(model_name=model_name)

# ğŸ”¹ Step 2: Load the FAISS index (path yahan daal de tu)
index_path = "faiss_index"
faiss_index = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)

# ğŸ”¹ Step 3: Access documents and print content + metadata
print("\nğŸ” Documents and Metadata:\n" + "="*60)
for doc_id, doc in faiss_index.docstore._dict.items():
    print(f"ğŸ†” ID: {doc_id}")
    print(f"ğŸ“„ Content: {doc.page_content}")
    print(f"ğŸ“ Metadata: {doc.metadata}")
    print("-" * 60)

# ğŸ”¹ Step 4: Access and print embeddings
print("\nğŸ§  Embeddings (Vectors):\n" + "="*60)
vectors = faiss_index.index.reconstruct_n(0, faiss_index.index.ntotal)

# Done
print(f"\nâœ… Total documents: {len(faiss_index.docstore._dict)}")
print(f"âœ… Total vectors: {faiss_index.index.ntotal}")
